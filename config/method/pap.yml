description: "PAP (Persuasive Adversarial Prompt): Using human persuasion techniques to jailbreak LLMs"
config:
  # =========================
  # Attack Model Configuration
  # =========================
  attack_model:
    type: "whitebox"                   # "blackbox" or "whitebox"
    
    # Blackbox attack model settings
    blackbox:
      provider: "gemini"               # "openai", "anthropic", "cohere", "together", "gemini"
      name: "gemini-2.5-flash"         # Model name for the provider
      api_key: null                     # Set via GEMINI_API_KEY, OPENAI_API_KEY, etc.
      use_proxy: false                 # Whether to use proxy
      max_tokens: 2500                 # Max tokens for attack model generation
      temperature: 1.0                 # Sampling temperature
      top_p: 1.0                       # Nucleus sampling
      frequency_penalty: 0              # Frequency penalty
      presence_penalty: 0               # Presence penalty
      rate_limit_backoff_base: 1.0     # Rate limit backoff base
      rate_limit_backoff_max: 60.0     # Rate limit backoff max
      rate_limit_jitter: 0.2           # Rate limit jitter
    
    # Whitebox attack model settings (aligned with CKA-Agent controller_model)
    whitebox:
      name: "huihui-ai/Qwen3-32B-abliterated"  # HF model name
      device_map: "auto"               # Multi-GPU auto mapping
      max_new_tokens: 4096             # Max new tokens for generation (same as original)
      max_model_len: 4096             # Max model length (same as original)
      temperature: 1.0                 # High temperature for diversity (same as original)
      top_p: 1.0                       # Nucleus sampling (same as original)
      input_max_length: 4096         # Max model length (from CKA)
      use_vllm: true                   # Whether to use vLLM for accelerated inference
      enable_thinking: true          # Enable thinking mode for Qwen3 (Qwen3 uses opposite logic!)
      remove_thinking: true            # Remove thinking part from response
      hf_token: null # Set via HF_TOKEN environment variable
      
      # vLLM engine configuration (aligned with CKA)
      vllm_kwargs:                     # Additional vLLM configuration parameters
        tensor_parallel_size: 1        # Multi-GPU for attack model (from CKA)
        trust_remote_code: true
        gpu_memory_utilization: 0.9    # GPU memory utilization ratio (from CKA)
        max_model_len: 4096          # Maximum model length (from CKA)
        enforce_eager: false           # Enable CUDA graph optimization (from CKA)
        disable_custom_all_reduce: true
        disable_log_stats: true
        
  
  # =========================
  # Persuasion Technique Selection
  # =========================
  num_techniques: 1                    # Number of top techniques to use
  technique_selection: "custom"       # "top_5", "random", "all", "custom"
  
  
  # =========================
  # Technique-Specific Parameters
  # =========================
  techniques:
    # - "Logical Appeal"                 # Only use Logical Appeal technique
    # - "Authority Endorsement"               # Only use Emotional Appeal technique
    # - "Misrepresentation"
    # - "Evidence-based Persuasion"
    - "Expert Endorsement"
  
  # =========================
  # Generation Parameters (for persuasion prompt generation)
  # =========================
  temperature: 1.0                     # High temperature for diversity (same as original)
  max_tokens: 2500                     # Max tokens for persuasion generation (same as original)
  top_p: 1.0                          # Nucleus sampling (same as original)
  frequency_penalty: 0                # Frequency penalty (same as original)
  presence_penalty: 0                  # Presence penalty (same as original)
  
  
  # =========================
  # Timeout and Retry Settings
  # =========================
  timeout: 30                          # Timeout for model inference
  max_retries: 3                       # Max retries for failed requests
  
  # =========================
  # Debugging and Logging
  # =========================
  verbose: true                       # Show detailed progress
  save_intermediate: true             # Save intermediate results
