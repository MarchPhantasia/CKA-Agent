"""
CKA-Agent (Correlated Knowledge Attack Agent) Method Implementation
A tree-search based jailbreak method using iterative decomposition and synthesis.
"""

from typing import Dict, Any, List, Optional, Tuple
import time
import json
import logging
from dataclasses import dataclass, field
from enum import Enum
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import math
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig
import torch
import threading
from collections import defaultdict
from methods.proposed.core_modules.controller_llm import ControllerLLM

# from methods.proposed.core_modules.target_llm import TargetModel
from methods.proposed.core_modules.agent_evaluator import Evaluator
from abstract_method import AbstractJailbreakMethod
from methods.proposed.core_modules.utils import ActionType
from methods.proposed.core_modules.synthesizer import Synthesizer
from methods.proposed.core_modules.utils import TreeNode
from model.model_loader import WhiteBoxModel, BlackBoxModel


# ============================================================================
# Data Structures
# ============================================================================

# class ActionType(Enum):
#     """Types of actions the agent can take."""
#     DECOMPOSE = "decompose"        # Break down into sub-goals
#     QUERY_TARGET = "query_target"  # Query the target LLM
#     USE_TOOL = "use_tool"         # Use external tool
#     SYNTHESIZE = "synthesize"      # Synthesize final answer
#     REFLECT = "reflect"            # Reflect on failure


@dataclass
class Memory:
    """Episodic memory for storing reflections from failures."""

    reflections: List[Dict[str, Any]] = field(default_factory=list)
    max_size: int = 100

    def add_reflection(self, reflection: Dict[str, Any]):
        """Add a reflection to memory with size management."""
        reflection["timestamp"] = time.time()
        self.reflections.append(reflection)
        if len(self.reflections) > self.max_size:
            self.reflections.pop(0)  # Remove oldest

    def get_relevant_reflections(
        self, query: str, top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """Retrieve relevant reflections for the current query."""
        # TODO: Implement semantic similarity search
        # For now, return most recent reflections
        return self.reflections[-top_k:] if self.reflections else []

    def get_formatted_reflections(self, query: str, top_k: int = 3) -> str:
        """Get formatted reflections as string for prompt inclusion."""
        relevant = self.get_relevant_reflections(query, top_k)
        if not relevant:
            return ""

        formatted = []
        for r in relevant:
            formatted.append(f"- {r.get('lesson_learned', '')}")

        return "Previous learnings:\n" + "\n".join(formatted)


# ============================================================================
# Core Modules
# ============================================================================


class ToolInterface:
    """Interface for external tools."""

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logging.getLogger(self.__class__.__name__)
        self.available_tools = self.config.get("available_tools", [])

    def check_tool_needed(
        self, state: Dict[str, Any], controller: ControllerLLM
    ) -> Tuple[bool, Optional[str]]:
        """Check if external tool is needed and which one."""
        return False, None

    def call_tool(self, tool_name: str, query: str) -> str:
        """Call external tool."""
        # TODO: Implement actual tool calling
        self.logger.info(f"Would call tool {tool_name} with query: {query}")
        return f"[Tool {tool_name} result placeholder]"


# ============================================================================
# Main CKA-Agent Method
# ============================================================================


class CKAAgentMethod(AbstractJailbreakMethod):
    """
    CKA-Agent: Correlated Knowledge Attack Agent
    A tree-search based jailbreak method using MCTS-inspired search with reflection.
    """

    def __init__(
        self, name: str = "cka-agent", config: Dict[str, Any] = None, model=None
    ):
        """Initialize CKA-Agent method."""
        default_config = {
            # Controller/Attack model settings will be provided via method config (attack_model)
            # Search settings
            "max_depth": 5,
            "max_iterations": 5,
            "exploration_weight": 1.414,
            "num_branches": 3,
            "single_path_confidence": 0.8,
            # Memory settings
            "memory_size": 100,
            "use_reflection": True,
            # Tool settings
            "use_external_tools": False,
            "available_tools": [],
        }

        if config:
            default_config.update(config)

        super().__init__(name, default_config, model)

        # ===== GPU allocation using centralized manager =====
        from utils.gpu_manager import get_gpu_manager

        self.gpu_manager = get_gpu_manager()

        # Get GPU allocations for this method
        controller_allocation = self.gpu_manager.get_allocation(f"{name}_controller")
        judge_allocation = self.gpu_manager.get_allocation(f"{name}_judge")

        # Set GPU assignments
        if controller_allocation:
            self.controller_gpu = controller_allocation.gpu_ids[0]
            self.logger.info(
                f"[CKA-Agent] Controller GPU allocation: GPU {self.controller_gpu}"
            )
        else:
            self.controller_gpu = "0"  # Fallback
            self.logger.warning(
                "[CKA-Agent] No controller GPU allocation found, using fallback"
            )

        if judge_allocation:
            self.judge_gpus = judge_allocation.gpu_ids
            self.logger.info(
                f"[CKA-Agent] Judge GPU allocation: GPUs {self.judge_gpus}"
            )
        else:
            self.judge_gpus = [self.controller_gpu]  # Fallback to controller GPU
            self.logger.warning(
                "[CKA-Agent] No judge GPU allocation found, using controller GPU"
            )
        # ===== END GPU allocation =====

        # ---- Target model comes from framework (supports both blackbox and whitebox) ----
        if not isinstance(self.model, (BlackBoxModel, WhiteBoxModel)):
            raise ValueError(
                "CKA-Agent requires target model as BlackBoxModel or WhiteBoxModel"
            )

        # ---- Build controller LM (whitebox only) from method config ----
        ctrl_cfg = self.config.get("controller_model", {}) or {}
        if not ctrl_cfg.get("name") or str(ctrl_cfg.get("name")).strip() == "":
            raise ValueError(
                f"CKA controller_model.name is empty; controller_model={ctrl_cfg}"
            )
        self.enable_tool_calling = bool(ctrl_cfg.get("enable_tool_calling", False))
        # self.attack_lm = WhiteBoxModel(
        #     ctrl_cfg.get("name", ""),
        #     {
        #         "use_vllm": ctrl_cfg.get("use_vllm", False),
        #         "vllm_kwargs": ctrl_cfg.get("vllm_kwargs", {}),
        #         "device_map": ctrl_cfg.get("device_map", None),
        #         "max_length": ctrl_cfg.get("max_tokens", 1024),
        #         "temperature": ctrl_cfg.get("temperature", 0.7),
        #         "top_p": ctrl_cfg.get("top_p", 0.9),
        #         "do_sample": ctrl_cfg.get("do_sample", True),
        #         "hf_token": ctrl_cfg.get("hf_token"),
        #         "controller_compat": True,
        #         "input_max_length": int(ctrl_cfg.get("input_max_length", 2048)),
        #     },
        # )

        # self.attack_lm.load(ctrl_cfg.get("hf_token"))
        # self.attack_template_name = self.attack_lm.model_name
        # ===== NEW: Prepare controller config with GPU allocation =====
        controller_config = {
            "use_vllm": ctrl_cfg.get("use_vllm", False),
            "vllm_kwargs": ctrl_cfg.get("vllm_kwargs", {}),
            "device_map": ctrl_cfg.get("device_map", None),
            "max_length": ctrl_cfg.get("max_tokens", 1024),
            "temperature": ctrl_cfg.get("temperature", 0.7),
            "top_p": ctrl_cfg.get("top_p", 0.9),
            "do_sample": ctrl_cfg.get("do_sample", True),
            "hf_token": ctrl_cfg.get("hf_token"),
            "controller_compat": True,
            "input_max_length": int(ctrl_cfg.get("input_max_length", 2048)),
        }

        # Inject GPU allocation for controller
        if controller_config.get("use_vllm", False):
            # Force tensor_parallel_size to 1 for controller (single GPU)
            if "vllm_kwargs" not in controller_config:
                controller_config["vllm_kwargs"] = {}
            controller_config["vllm_kwargs"]["tensor_parallel_size"] = 1

        # Always set GPU override for controller (regardless of vLLM usage)
        controller_config["_cka_gpu_override"] = self.controller_gpu

        self.logger.info(
            f"[CKA-Agent] Controller will use single GPU: {self.controller_gpu}"
        )
        # ===== END GPU allocation =====

        self.attack_lm = WhiteBoxModel(ctrl_cfg.get("name", ""), controller_config)

        self.attack_lm.load(ctrl_cfg.get("hf_token"))
        self.attack_template_name = self.attack_lm.model_name

        # ---- Controller uses framework whitebox under the hood (no internal HF loads) ----
        # Pass the loaded attack_lm to avoid double initialization
        tools_enabled = self.enable_tool_calling
        available_tools = self.config.get("available_tools", []) or []
        tool_registry = None
        if tools_enabled:
            from methods.proposed.core_modules.tool import (
                ToolRegistry,
                # tool_web_search,
                # tool_fetch_content,
                tool_web_search_fetch,
                tool_read_file,
                tool_write_file,
            )

            tool_registry = ToolRegistry()
            for name in available_tools:
                if name == "web_search_fetch":
                    tool_registry.register(name, tool_web_search_fetch)
                elif name == "read_file":
                    tool_registry.register(name, tool_read_file)
                elif name == "write_file":
                    tool_registry.register(name, tool_write_file)

        # NEW: Pass whitebox_model to avoid double initialization
        self.controller = ControllerLLM(
            config=ctrl_cfg,
            tool_registry=tool_registry,
            whitebox_model=self.attack_lm,  # Reuse the loaded model
        )

        # # ---- Online judge for agent (distinct from evaluation phase) ----
        # online_judge_cfg = self.config.get("judge_model") or {}
        # self.evaluator = Evaluator(config={"judge_model": online_judge_cfg})

        # ---- Online judge for agent (distinct from evaluation phase) ----
        online_judge_cfg = self.config.get("judge_model") or {}

        # ===== NEW: Inject GPU allocation into judge config =====
        online_judge_cfg_with_gpu = online_judge_cfg.copy()

        # For vLLM: set tensor_parallel_size based on remaining GPUs
        if online_judge_cfg_with_gpu.get("use_vllm", False):
            if "vllm_kwargs" not in online_judge_cfg_with_gpu:
                online_judge_cfg_with_gpu["vllm_kwargs"] = {}

            # Set tensor_parallel_size to number of judge GPUs
            online_judge_cfg_with_gpu["vllm_kwargs"]["tensor_parallel_size"] = len(
                self.judge_gpus
            )

        # Always set GPU override for judge (regardless of vLLM usage)
        if online_judge_cfg_with_gpu.get("type") == "whitebox":
            online_judge_cfg_with_gpu["_cka_gpu_override"] = ",".join(self.judge_gpus)
            self.logger.info(f"[CKA-Agent] Judge will use GPUs: {self.judge_gpus}")
        # ===== END GPU injection =====

        self.evaluator = Evaluator(config={"judge_model": online_judge_cfg_with_gpu})

        # ---- Synthesizer uses controller chat ----
        self.synthesizer = Synthesizer(self.controller)
        self.tool_interface = ToolInterface(
            config={"available_tools": self.config.get("available_tools", [])}
        )
        self.memory = Memory(max_size=self.config["memory_size"])

        # Search tree
        self.tree = {}  # node_id -> TreeNode
        self.root_id = None

        # Thread-safe intermediate saver for per-sample files (referencing AutoDAN's approach)
        self._sample_locks = defaultdict(threading.Lock)
        self._thread_local = threading.local()

        # Output directory injected by main; fallback to current directory
        self.output_dir = getattr(self, "output_dir", os.getcwd())

        self.logger.info(f"Initialized CKA-Agent with config: {self.config}")

    def validate_config(self) -> bool:
        """Validate CKA-Agent configuration."""
        if not super().validate_config():
            return False

        # Validate specific config items
        required_fields = ["max_depth", "max_iterations"]
        for field in required_fields:
            if field not in self.config:
                self.logger.error(f"Missing required field: {field}")
                return False

        return True

    def _save_intermediate(
        self,
        iteration: int,
        best_node: Optional[TreeNode] = None,
        success: bool = False,
        asr_classification: str = "A",
        asr_confidence: float = 0.0,
    ) -> None:
        """
        Save intermediate results of CKA-Agent, referencing AutoDAN's approach.
        Key data to save: ASR, iteration, tree structure, branch information, sub-goals, and responses.

        Args:
            iteration: current iteration number
            best_node: current best node
            success: whether successful
            asr_classification: ASR classification result
            asr_confidence: ASR confidence score
        """
        try:
            # Get thread-local storage information
            sample_index = getattr(self._thread_local, "sample_index", 0)
            dataset_key = getattr(self._thread_local, "dataset_key", "unknown")

            # Use sample-specific lock to avoid conflicts
            with self._sample_locks[sample_index]:
                os.makedirs(self.output_dir, exist_ok=True)
                inter_path = os.path.join(
                    self.output_dir, f"inter_result_sample_{sample_index}.json"
                )

                # Calculate tree statistics
                tree_stats = self._calculate_tree_statistics()

                # Build best node information
                best_node_info = None
                if best_node:
                    best_node_info = {
                        "node_id": best_node.node_id,
                        "depth": best_node.depth,
                        "visit_count": best_node.visit_count,
                        "value_score": float(best_node.value_score),
                        "asr_classification": getattr(
                            best_node, "asr_classification", "A"
                        ),
                        "asr_confidence": float(
                            getattr(best_node, "asr_confidence", 0.0)
                        ),
                        "trajectory": best_node.trajectory_from_root,
                        "subgoals": best_node.state.get("sub_goals", []),
                        "responses": self._extract_responses_from_trajectory(best_node),
                        "synthesized_response": getattr(
                            best_node, "synthesized_response", ""
                        ),
                        "is_terminal": best_node.is_terminal,
                        "is_success": getattr(best_node, "is_success", False),
                    }

                # Build complete tree structure information
                tree_structure = {}
                for node_id, node in self.tree.items():
                    tree_structure[node_id] = {
                        "depth": node.depth,
                        "visit_count": node.visit_count,
                        "value_score": float(node.value_score),
                        "is_terminal": node.is_terminal,
                        "is_success": getattr(node, "is_success", False),
                        "asr_classification": getattr(node, "asr_classification", "A"),
                        "asr_confidence": float(getattr(node, "asr_confidence", 0.0)),
                        "parent_id": node.parent_id,
                        "children": node.children,
                        "action": node.action.get("content", "") if node.action else "",
                        "observation": (
                            node.observation[:500] if node.observation else ""
                        ),  # Truncate for saving
                        "subgoals": node.state.get("sub_goals", []),
                        "trajectory": node.trajectory_from_root,
                        "accumulated_context": (
                            node.accumulated_context[:1000]
                            if node.accumulated_context
                            else ""
                        ),  # Truncate for saving
                    }

                # Build iteration payload (sorted by importance)
                iteration_payload = {
                    # Most important information first
                    "iteration": int(iteration),
                    "asr_classification": str(asr_classification),
                    "asr_confidence": float(asr_confidence),
                    "success": bool(success),
                    # Tree structure statistics
                    "tree_size": tree_stats["total_nodes"],
                    "max_depth_reached": tree_stats["max_depth"],
                    "branches_count": tree_stats["total_branches"],
                    "terminal_nodes_count": tree_stats["terminal_nodes"],
                    "success_nodes_count": tree_stats["success_nodes"],
                    # Current best node information
                    "best_node": best_node_info,
                    # Complete tree structure (for analyzing branching effectiveness)
                    "tree_structure": tree_structure,
                    # Memory and tool information
                    "memory_reflections": [
                        {
                            "lesson_learned": r.get("lesson_learned", ""),
                            "timestamp": r.get("timestamp", 0),
                            "depth": r.get("depth", 0),
                        }
                        for r in self.memory.reflections[
                            -10:
                        ]  # Save only the last 10 reflections
                    ],
                    "tool_usage": [],  # TODO: If tools are used, record tool usage
                    # Metadata
                    "sample_index": int(sample_index),
                    "dataset_key": dataset_key,
                    "timestamp": time.time(),
                    "processing_time": getattr(self, "_current_processing_time", 0.0),
                }

                # Save in append mode (JSONL format)
                with open(inter_path, "a", encoding="utf-8") as f:
                    json_str = json.dumps(iteration_payload, ensure_ascii=False)
                    f.write(json_str + "\n")
                    f.flush()  # Ensure immediate write to disk

                self.logger.debug(
                    f"Saved intermediate results for iteration {iteration}"
                )

        except Exception as e:
            # Do not interrupt the main search loop
            self.logger.debug(
                f"Failed to save intermediate results at iteration {iteration}: {e}"
            )

    def _calculate_tree_statistics(self) -> Dict[str, Any]:
        """Calculate tree statistics"""
        stats = {
            "total_nodes": len(self.tree),
            "max_depth": 0,
            "total_branches": 0,
            "terminal_nodes": 0,
            "success_nodes": 0,
        }

        for node in self.tree.values():
            stats["max_depth"] = max(stats["max_depth"], node.depth)
            stats["total_branches"] += len(node.children)

            if node.is_terminal:
                stats["terminal_nodes"] += 1

            if getattr(node, "is_success", False):
                stats["success_nodes"] += 1

        return stats

    def _extract_responses_from_trajectory(self, node: TreeNode) -> List[str]:
        """Extract response information from trajectory"""
        responses = []
        for node_id in node.trajectory_from_root:
            if node_id in self.tree:
                tree_node = self.tree[node_id]
                if tree_node.observation:
                    # Truncate response content
                    responses.append(tree_node.observation[:200])
        return responses

    def initialize_tree(self, query: str) -> str:
        """Initialize search tree with root node."""
        self.tree = {}
        self.root_id = "root"

        root_node = TreeNode(
            node_id=self.root_id,
            parent_id=None,
            depth=0,
            state={
                "goal": query,
                "observations": [],
                "sub_goals": [],
                "tool_results": {},
            },
            trajectory_from_root=[self.root_id],
        )

        self.tree[self.root_id] = root_node
        return self.root_id

    def select_leaf_node(self) -> TreeNode:
        """Select leaf node to expand using UCT, traversing from root to leaf."""
        current = self.tree[self.root_id]

        path = [current.node_id]

        # Traverse down the tree using UCT until we reach a leaf
        while current.children and not current.is_terminal:
            # Select child with highest UCT score
            best_child_id = None
            best_score = -float("inf")

            for child_id in current.children:
                child = self.tree[child_id]
                score = child.uct_score(
                    current.visit_count, self.config["exploration_weight"]
                )
                if score > best_score:
                    best_score = score
                    best_child_id = child_id

            current = self.tree[best_child_id]
            path.append(current.node_id)

        self.logger.info(f"Selected path: {' -> '.join(path)}")
        return current

    def expand_until_terminal(self, start_node: TreeNode) -> Tuple[TreeNode, bool]:
        """
        Expand from start_node downward until reaching terminal or max depth.
        Returns: (terminal_node, success_flag)
        """
        current_node = start_node

        # original code
        # while (
        #     not current_node.is_terminal
        #     and current_node.depth < self.config["max_depth"]
        # ):
        #     self.logger.info(
        #         f"Expanding node {current_node.node_id} at depth {current_node.depth}"
        #     )

        #     # Pre-expansion analysis with separate focused prompts
        #     is_terminal = self.controller.check_terminal_state(
        #         current_node, self.memory
        #     )

        #     if is_terminal:
        #         current_node.is_terminal = True
        #         self.logger.info(f"Node {current_node.node_id} is terminal")
        #         break

        # New version include skip root node terminal state check
        while (
            not current_node.is_terminal
            and current_node.depth < self.config["max_depth"]
        ):
            self.logger.info(
                f"Expanding node {current_node.node_id} at depth {current_node.depth}"
            )

            # ===== NEW: Skip terminal check for root node (depth=0) =====
            # Root node should always be expanded to avoid premature stopping
            if current_node.depth == 0:
                self.logger.info(
                    f"[Expand] Skipping terminal check for root node (depth=0)"
                )
                is_terminal = False
            else:
                # Pre-expansion analysis with separate focused prompts
                is_terminal = self.controller.check_terminal_state(
                    current_node, self.memory
                )
            # ===== END skip root terminal check =====

            if is_terminal:
                current_node.is_terminal = True
                self.logger.info(
                    f"Node {current_node.node_id} is terminal at depth {current_node.depth}"
                )
                break

            # Generate expansion actions with integrated strategy determination
            actions = self.controller.generate_expansion_actions(
                current_node, self.memory
            )

            # Log the expansion details
            num_branches = len(actions)
            strategy = actions[0].get("strategy", "UNKNOWN") if actions else "UNKNOWN"
            self.logger.info(
                f"Expansion: {strategy} strategy with {num_branches} action(s)"
            )

            if not actions:
                current_node.is_terminal = True
                break

            # Create child nodes
            children_created = []
            for i, action in enumerate(actions):
                child_id = f"{current_node.node_id}_c{i}_d{current_node.depth+1}"

                # Update state with new sub-goal
                new_state = current_node.state.copy()
                new_state["sub_goals"] = new_state.get("sub_goals", []) + [
                    action["content"]
                ]

                # Create trajectory
                new_trajectory = current_node.trajectory_from_root + [child_id]

                child_node = TreeNode(
                    node_id=child_id,
                    parent_id=current_node.node_id,
                    depth=current_node.depth + 1,
                    state=new_state,
                    action=action,
                    trajectory_from_root=new_trajectory,
                    accumulated_context=current_node.accumulated_context
                    + f"\n{action['content']}",
                )

                # Execute action - query target model (append length/style instruction to preserve behavior)
                self.logger.info(f"Querying target with: {action['content'][:100]}...")
                # Add length/style instruction for concise responses
                length_instruction = "\n\nProvide a complete yet concise answer in around 100 words, only include essential information to answer the question, no need to provide too much details. No more than 200 words."
                target_prompt = action["content"] + length_instruction

                # import pdb; pdb.set_trace()
                # Get raw response from target
                raw_observation = self.model.generate(target_prompt)
                self.logger.info(f"Got raw response: {len(raw_observation)} chars")

                max_info_length = 2000
                extracted_observation = (
                    raw_observation[:max_info_length]
                    if len(raw_observation) > max_info_length
                    else raw_observation
                )

                # extracted_observation = self.controller.extract_key_information(
                #     observation=raw_observation,
                #     query=action["content"],
                #     max_length=max_info_length,
                # )

                child_node.observation = extracted_observation
                self.logger.info(
                    f"Stored extracted observation: {len(extracted_observation)} chars"
                )

                # Update accumulated context
                child_node.accumulated_context += f"\nResponse: {extracted_observation}"

                self.tree[child_id] = child_node
                current_node.children.append(child_id)
                children_created.append(child_node)

            # =========== Original Sequential Evaluation ===========
            # # Evaluate all children
            # best_child = None
            # best_value = -float("inf")

            # for child in children_created:
            #     # Hybrid evaluation
            #     node_value = self.evaluator.evaluate_node(child, self.controller)
            #     child.value_score = node_value
            #     child.visit_count = 1

            #     self.logger.info(f"Child {child.node_id} evaluated: {node_value:.3f}")

            #     if node_value > best_value:
            #         best_value = node_value
            #         best_child = child
            # ======================================

            # =========== New Parallel Evaluation ===========
            self.logger.info(
                f"[Batch Evaluation] Evaluating {len(children_created)} children nodes"
            )
            node_values = self.evaluator.evaluate_nodes_batch(
                children_created, self.controller
            )

            # Find best child and update values
            best_child = None
            best_value = -float("inf")

            for child, node_value in zip(children_created, node_values):
                child.value_score = node_value
                child.visit_count = 1

                self.logger.info(f"Child {child.node_id} evaluated: {node_value:.3f}")

                if node_value > best_value:
                    best_value = node_value
                    best_child = child

            self.logger.info(
                f"[Batch Evaluation Complete] Best child: {best_child.node_id} (score: {best_value:.3f})"
            )
            # ======================================

            # Continue with best child for single-path expansion
            if num_branches == 1 or not best_child:
                current_node = children_created[0] if children_created else current_node
            else:
                current_node = best_child

        # Mark as terminal if max depth reached
        if current_node.depth >= self.config["max_depth"]:
            current_node.is_terminal = True
            self.logger.info(f"Node {current_node.node_id} reached max depth")

        return current_node, False

    def backpropagate(self, node: TreeNode, value: float):
        """Backpropagate value from node to root."""
        current = node
        while current:
            current.visit_count += 1
            current.value_score += value

            self.logger.debug(
                f"Backprop: {current.node_id} - visits={current.visit_count}, total_value={current.value_score:.3f}"
            )

            if current.parent_id:
                current = self.tree.get(current.parent_id)
            else:
                break

    def reflect_on_failure(self, node: TreeNode):
        """Generate and store reflection from failed path."""
        if not self.config["use_reflection"]:
            return

        # Get trajectory from root to failed node
        trajectory = self._get_trajectory(node)

        # Generate reflection
        reflection = self.controller.reflect_on_failure(
            trajectory, self.tree[self.root_id].state["goal"]
        )

        # Store in memory with metadata
        reflection["failed_node_id"] = node.node_id
        reflection["depth"] = node.depth
        self.memory.add_reflection(reflection)

        self.logger.info(
            f"Generated reflection: {reflection.get('lesson_learned', '')[:100]}..."
        )

    def _get_trajectory(self, node: TreeNode) -> List[TreeNode]:
        """Get path from root to given node."""
        trajectory = []
        for node_id in node.trajectory_from_root:
            if node_id in self.tree:
                trajectory.append(self.tree[node_id])
        return trajectory

    def generate_jailbreak(self, query: str, **kwargs) -> Dict[str, Any]:
        """
        Generate jailbreak using tree search.

        Args:
            query (str): Original harmful query
            **kwargs: Additional parameters

        Returns:
            Dict[str, Any]: Result containing jailbreak and metadata
        """
        start_time = time.time()

        # Initialize result
        result = {
            "original_query": query,
            "jailbreak_prompt": None,
            "response": None,
            "success": False,
            "metadata": {
                "method": self.name,
                "timestamp": start_time,
                "processing_time": 0,
                "iterations": 0,
                "tree_size": 0,
                "max_depth_reached": 0,
                "category": kwargs.get("category", "unknown"),
                "source": kwargs.get("source", "unknown"),
            },
            "error": None,
        }

        try:
            # Initialize search tree
            self.initialize_tree(query)

            # Record start time to calculate processing time
            self._current_processing_time = 0.0
            search_start_time = time.time()

            # Main search loop
            for iteration in range(self.config["max_iterations"]):
                self.logger.info(f"\n{'='*60}")
                self.logger.info(
                    f"Iteration {iteration + 1}/{self.config['max_iterations']}"
                )

                # 1. Selection - find best leaf node to expand
                selected_leaf = self.select_leaf_node()
                self.logger.info(
                    f"Selected leaf: {selected_leaf.node_id} at depth {selected_leaf.depth}"
                )

                # Skip if already terminal
                if selected_leaf.is_terminal:
                    self.logger.info(
                        f"Selected node is already terminal, skipping expansion"
                    )
                    continue

                # 2. Expand from selected leaf until terminal
                terminal_node, success = self.expand_until_terminal(selected_leaf)

                # Update max depth reached
                result["metadata"]["max_depth_reached"] = max(
                    result["metadata"]["max_depth_reached"], terminal_node.depth
                )

                # 3. Process terminal node
                if terminal_node.depth > 0:  # Not root node
                    # Always synthesize when reaching terminal
                    trajectory = self._get_trajectory(terminal_node)
                    synthesized_response = self.synthesizer.synthesize_from_trajectory(
                        trajectory, query
                    )

                    # # Check success on the synthesized response
                    # is_success = self.evaluator.check_jailbreak_success(
                    #     synthesized_response,  # Check synthesized content, not raw observation
                    #     query
                    # )

                    # Check success using ASR judge
                    is_success, classification, confidence, reasoning = (
                        self.evaluator.check_jailbreak_success(
                            synthesized_response, query
                        )
                    )
                    # import pdb; pdb.set_trace()

                    # Store classification for later comparison
                    terminal_node.asr_classification = classification
                    terminal_node.asr_confidence = confidence
                    terminal_node.synthesized_response = synthesized_response

                    # Update processing time
                    self._current_processing_time = time.time() - search_start_time

                    # Save intermediate results (after each ASR evaluation)
                    if bool(self.config.get("save_intermediate", False)):
                        try:
                            self._save_intermediate(
                                iteration=iteration + 1,
                                best_node=terminal_node,
                                success=is_success,
                                asr_classification=classification,
                                asr_confidence=confidence,
                            )
                        except Exception as e:
                            self.logger.debug(
                                f"Failed to save intermediate results: {e}"
                            )

                    if is_success:  # Only "D" classification by default
                        # Success case - found full success
                        result["jailbreak_prompt"] = synthesized_response
                        result["response"] = synthesized_response
                        result["success"] = True
                        result["metadata"]["asr_classification"] = classification
                        result["metadata"]["asr_confidence"] = confidence

                        # Mark terminal node as successful
                        terminal_node.is_success = True

                        # Backpropagate high reward for full success
                        reward = (
                            1.0 if classification == "D" else 0.8
                        )  # Slightly lower for "C" if configured
                        self.backpropagate(terminal_node, reward)

                        self.logger.info(
                            f"ðŸŽ¯ Jailbreak successful! Classification: {classification} "
                            f"(confidence: {confidence:.2f})"
                        )
                        self.logger.info(f"Success after {iteration + 1} iterations")
                        break
                    else:
                        # Not full success, but store for potential fallback
                        self.logger.info(
                            f"Terminal node {terminal_node.node_id} - Classification: {classification} "
                            f"(not full success, continuing search)"
                        )

                        # Store as potential fallback
                        terminal_node.is_fallback_candidate = True

                        # Generate reflection from non-success
                        if self.config["use_reflection"]:
                            self.reflect_on_failure(terminal_node)

                        # Backpropagate penalty based on classification
                        penalty_map = {
                            "A": -0.5,
                            "B": -0.2,
                            "C": -0.1,
                        }  # C gets small positive score
                        penalty = penalty_map.get(classification, -0.5)
                        self.backpropagate(terminal_node, penalty)
                else:
                    # Handle case where we selected root as terminal (shouldn't happen)
                    self.logger.warning("Selected root node as terminal, skipping")
                    continue

                result["metadata"]["iterations"] = iteration + 1
                result["metadata"]["tree_size"] = len(self.tree)

            # Final attempt if no success
            if not result["success"]:
                best_node = self._find_best_terminal_node()
                if best_node and hasattr(best_node, "synthesized_response"):
                    result["jailbreak_prompt"] = best_node.synthesized_response
                    result["response"] = best_node.synthesized_response
                    result["metadata"][
                        "asr_classification"
                    ] = best_node.asr_classification
                    result["metadata"]["asr_confidence"] = best_node.asr_confidence
                    result["metadata"]["fallback"] = True

                    self.logger.info(
                        f"Using best fallback with classification: {best_node.asr_classification}"
                    )
                else:
                    result["response"] = "No successful jailbreak found"
                    result["metadata"]["asr_classification"] = "A"
                    result["response"] = result["jailbreak_prompt"]
                    self.logger.info("Using best terminal node for final result")

            # Update statistics
            self.update_stats(success=result["success"], error=False)

        except Exception as e:
            error_msg = f"Error in CKA-Agent: {str(e)}"
            self.logger.error(error_msg)
            import traceback

            self.logger.error(traceback.format_exc())
            result["error"] = error_msg
            result["success"] = False
            self.update_stats(success=False, error=True)

        # Calculate processing time
        result["metadata"]["processing_time"] = time.time() - start_time
        self.logger.info(
            f"Total processing time: {result['metadata']['processing_time']:.2f}s"
        )
        self.logger.info(f"Tree size: {len(self.tree)} nodes")

        return result

    # def _find_best_terminal_node(self) -> Optional[TreeNode]:
    #     """Find best terminal node in tree based on average value."""
    #     best_node = None
    #     best_avg_value = -float('inf')

    #     for node in self.tree.values():
    #         if node.is_terminal and node.visit_count > 0:
    #             avg_value = node.value_score / node.visit_count
    #             if avg_value > best_avg_value:
    #                 best_avg_value = avg_value
    #                 best_node = node

    #     if best_node:
    #         self.logger.info(f"Best terminal node: {best_node.node_id} with avg value {best_avg_value:.3f}")

    #     return best_node

    def _find_best_terminal_node(self) -> Optional[TreeNode]:
        """
        Find best terminal node based on ASR classification priority.
        Priority: D > C > B > A
        Within same classification, prefer higher confidence.
        """
        best_node = None
        best_classification = "A"
        best_confidence = 0.0

        classification_priority = {"D": 4, "C": 3, "B": 2, "A": 1}

        for node in self.tree.values():
            if not node.is_terminal:
                continue

            # Check if node has ASR evaluation
            if not hasattr(node, "asr_classification"):
                continue

            node_class = node.asr_classification
            node_conf = node.asr_confidence

            # Compare classifications
            if classification_priority.get(node_class, 0) > classification_priority.get(
                best_classification, 0
            ):
                # Better classification found
                best_node = node
                best_classification = node_class
                best_confidence = node_conf
            elif node_class == best_classification and node_conf > best_confidence:
                # Same classification but higher confidence
                best_node = node
                best_confidence = node_conf

        if best_node:
            self.logger.info(
                f"Best fallback node: {best_node.node_id} with "
                f"classification {best_classification} (confidence: {best_confidence:.2f})"
            )

        return best_node

    def prepare_prompt(self, query: str, **kwargs) -> str:
        """CKA-Agent does not use traditional prompt preparation."""
        return query

    def generate_jailbreak_batch(
        self, queries: List[str], **kwargs
    ) -> List[Dict[str, Any]]:
        """Dataset-level batch processing, following framework conventions; when attack side uses vLLM, disable concurrency to avoid resource contention."""
        batch_size = getattr(self.model, "batch_size", 1)
        try:
            if hasattr(self, "attack_lm") and getattr(
                self.attack_lm, "use_vllm", False
            ):
                if batch_size != 1:
                    self.logger.info(
                        f"attack.use_vllm=True -> forcing dataset batch_size from {batch_size} to 1 (disable threading)"
                    )
                batch_size = 1
        except Exception:
            pass

        # Get global base index and dataset key
        base_index = int(kwargs.get("base_index", 0))
        dataset_key = kwargs.get("dataset_key", "unknown")

        results: List[Dict[str, Any]] = []
        if batch_size <= 1:
            # Serial processing
            for i, q in enumerate(queries):
                # Set thread-local storage (referencing AutoDAN's approach)
                self._thread_local.sample_index = base_index + i
                self._thread_local.dataset_key = dataset_key
                results.append(self.generate_jailbreak(q, **kwargs))
            return results

        # Batch execution
        for i in range(0, len(queries), batch_size):
            sub_qs = queries[i : i + batch_size]
            for j, q in enumerate(sub_qs):
                # Set thread-local storage
                self._thread_local.sample_index = base_index + i + j
                self._thread_local.dataset_key = dataset_key
                results.append(self.generate_jailbreak(q, **kwargs))
        return results

    def teardown(self) -> None:
        """Release controller and evaluator resources to free GPU/CPU memory."""
        try:
            self.logger.info("[CKA-Agent] Releasing resources...")

            # Release evaluator first (contains ASR judge model)
            if hasattr(self, "evaluator") and self.evaluator is not None:
                if hasattr(self.evaluator, "teardown") and callable(
                    getattr(self.evaluator, "teardown")
                ):
                    self.evaluator.teardown()
                self.evaluator = None

            # Release controller (contains controller model)
            if hasattr(self, "controller") and self.controller is not None:
                if hasattr(self.controller, "teardown") and callable(
                    getattr(self.controller, "teardown")
                ):
                    self.controller.teardown()
                self.controller = None

            # Release other components
            for attr in [
                "attack_lm",  # framework whitebox model
                "synthesizer",  # synthesizer using controller
            ]:
                if hasattr(self, attr):
                    setattr(self, attr, None)

            # Clear tree
            self.tree = {}

            # Force garbage collection
            import gc
            import torch

            gc.collect()
            try:
                torch.cuda.empty_cache()
            except Exception:
                pass

            self.logger.info("[CKA-Agent] Resources released successfully")

        except Exception as e:
            self.logger.warning(f"[CKA-Agent] Teardown warning: {e}")
